{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The Disaster ü§ñ\n## Ahmed Ashraf & Abdelrahman Lotfy","metadata":{}},{"cell_type":"markdown","source":"# Load Dependencies üì¶","metadata":{}},{"cell_type":"code","source":"import torch\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torchvision\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom IPython.display import clear_output\n%matplotlib inline\nimport time","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom DataSet","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, data_path, csv_file_path, transform=None):\n        self.data = pd.read_csv(csv_file_path)\n        self.transform = transform\n        self.data_path = data_path\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        img_name = self.data_path + self.data.iloc[index, 0] \n        image = Image.open(img_name)\n        label = self.data.iloc[index, 1]  \n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label","metadata":{"id":"MsiT_7aF2Gd_","execution":{"iopub.status.busy":"2023-08-03T16:44:42.868069Z","iopub.execute_input":"2023-08-03T16:44:42.869698Z","iopub.status.idle":"2023-08-03T16:44:42.880429Z","shell.execute_reply.started":"2023-08-03T16:44:42.869635Z","shell.execute_reply":"2023-08-03T16:44:42.878524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing The Data üíæ\n","metadata":{}},{"cell_type":"code","source":"csv_file_path = '/kaggle/input/ieeenu-cis-juniors-plant-binary-classification/PlantFinal Files-20230213T190104Z-001/Final Files/train.csv'\ndata_path = '/kaggle/input/ieeenu-cis-juniors-plant-binary-classification/PlantFinal Files-20230213T190104Z-001/Final Files/train/'\n\n\n# data augmentation for training\ntransform_train = transforms.Compose([\n    transforms.RandomHorizontalFlip(),    \n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),    \n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n\ntraindataset = CustomDataset(data_path,csv_file_path, transform=transform_train)\nvalidation_size = int(0.2 * len(traindataset))\ntrain_size = len(traindataset) - validation_size\ntrain_subset, validation_subset = torch.utils.data.random_split(traindataset, [train_size, validation_size])\nbatch_size = 16\ntrainloader = DataLoader(train_subset, batch_size=batch_size, shuffle=True, num_workers=2)","metadata":{"id":"RcgYoiCSMA_B","execution":{"iopub.status.busy":"2023-08-03T16:45:55.335898Z","iopub.execute_input":"2023-08-03T16:45:55.336375Z","iopub.status.idle":"2023-08-03T16:45:55.440481Z","shell.execute_reply.started":"2023-08-03T16:45:55.336332Z","shell.execute_reply":"2023-08-03T16:45:55.438935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization üñºÔ∏è","metadata":{"id":"iTwxGX9aMA_D"}},{"cell_type":"code","source":"def imshow(img, un):\n    if(un):\n        img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n# get some random training images\ndataiter = iter(trainloader)\nimages, labels = next(dataiter)\n\n\n# show images\nimshow(torchvision.utils.make_grid(images), True)\nimshow(torchvision.utils.make_grid(images), False)\nprint(images[0].shape)","metadata":{"id":"gmc9ub6vMA_D","outputId":"97f4694c-d8a6-498b-ef66-629509d56e54","execution":{"iopub.status.busy":"2023-08-03T16:48:18.856554Z","iopub.execute_input":"2023-08-03T16:48:18.857029Z","iopub.status.idle":"2023-08-03T16:48:20.708934Z","shell.execute_reply.started":"2023-08-03T16:48:18.856992Z","shell.execute_reply":"2023-08-03T16:48:20.707451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Distribution üìä","metadata":{}},{"cell_type":"code","source":"label_counts = {}\nfor batch in trainloader:\n    _, labels = batch  \n    for label in labels:\n        label = label.item()\n        if label in label_counts:\n            label_counts[label] += 1\n        else:\n            label_counts[label] = 1\n\nlabel_names = list(label_counts.keys())\nlabel_counts = list(label_counts.values())\nplt.figure(figsize=(8, 8))\nplt.pie(label_counts, labels=label_names, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')  \nplt.title('Label Distribution in the Training Dataset')\nplt.show()\n","metadata":{"id":"tWLkksjnt3_q","outputId":"e889b011-38ba-4919-d224-81a05f75e182","execution":{"iopub.status.busy":"2023-08-03T16:48:29.219792Z","iopub.execute_input":"2023-08-03T16:48:29.220384Z","iopub.status.idle":"2023-08-03T16:49:09.017709Z","shell.execute_reply.started":"2023-08-03T16:48:29.220332Z","shell.execute_reply":"2023-08-03T16:49:09.015811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Balancing Classes ‚öñÔ∏è ","metadata":{}},{"cell_type":"code","source":"labels = [data_label for _, data_label in train_subset]\ncount_class_0 = labels.count(0)\ncount_class_1 = labels.count(1)\nnum_samples_to_keep = min(count_class_0, count_class_1\nindices_class_0 = [i for i, label in enumerate(labels) if label == 0]\nindices_class_1 = [i for i, label in enumerate(labels) if label == 1]\nbalanced_indices = np.random.choice(indices_class_1, size=num_samples_to_keep, replace=False)\nbalanced_indices = list(balanced_indices)\nbalanced_indices.extend(np.random.choice(indices_class_0, size=num_samples_to_keep, replace=False))\nbalanced_dataset = [train_subset[i] for i in balanced_indices]","metadata":{"id":"o9vDoZNNvFhf","execution":{"iopub.status.busy":"2023-08-03T16:50:02.347185Z","iopub.execute_input":"2023-08-03T16:50:02.347697Z","iopub.status.idle":"2023-08-03T16:50:38.854114Z","shell.execute_reply.started":"2023-08-03T16:50:02.347655Z","shell.execute_reply":"2023-08-03T16:50:38.852939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoaders üîß","metadata":{"id":"WXi8vbl_MA_C"}},{"cell_type":"code","source":"batch_size = 16\n# Load the train dataset into a DataLoader\ntrainloader = DataLoader(balanced_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n# Load the validation dataset into a DataLoader\ncrossloader = DataLoader(validation_subset, batch_size=32, shuffle=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Class Distribution After Balancing üìä","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\n\nlabel_counts = {}\nfor batch in trainloader:\n    _, labels = batch  \n    for label in labels:\n        label = label.item()\n        if label in label_counts:\n            label_counts[label] += 1\n        else:\n            label_counts[label] = 1\n\nlabel_names = list(label_counts.keys())\nlabel_counts = list(label_counts.values())\nplt.figure(figsize=(8, 8))\nplt.pie(label_counts, labels=label_names, autopct='%1.1f%%', startangle=140)\nplt.axis('equal')  \nplt.title('Label Distribution in the Training Dataset')\nplt.show()\n","metadata":{"id":"14JOHGItw42O","outputId":"e8b9ef0e-a736-4e82-a12e-508bf47213d5","execution":{"iopub.status.busy":"2023-08-03T16:50:38.856396Z","iopub.execute_input":"2023-08-03T16:50:38.857193Z","iopub.status.idle":"2023-08-03T16:50:41.544107Z","shell.execute_reply.started":"2023-08-03T16:50:38.857152Z","shell.execute_reply":"2023-08-03T16:50:41.542697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Initialize counters\ncount_label_1 = 0\ncount_label_0 = 0\n\nfor batch_idx, (data, labels) in enumerate(trainloader):\n    count_label_1 += (labels == 1).sum().item()\n    count_label_0 += (labels == 0).sum().item()\n\n# Print the counts\nprint(\"Count of labeled data with Label 1:\", count_label_1)\nprint(\"Count of labeled data with Label 0:\", count_label_0)\n","metadata":{"id":"UE4T_3a1z9wK","execution":{"iopub.status.busy":"2023-08-03T17:19:12.833496Z","iopub.execute_input":"2023-08-03T17:19:12.833979Z","iopub.status.idle":"2023-08-03T17:19:15.363862Z","shell.execute_reply.started":"2023-08-03T17:19:12.833934Z","shell.execute_reply":"2023-08-03T17:19:15.360862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"6BSRGz_D-J2Q"}},{"cell_type":"code","source":"import torch.nn as nn\n","metadata":{"id":"GY_2rDhvypjC","outputId":"e898e10e-1b54-4f0e-98c9-36ac678c9fcb","execution":{"iopub.status.busy":"2023-08-03T13:21:51.105419Z","iopub.execute_input":"2023-08-03T13:21:51.105845Z","iopub.status.idle":"2023-08-03T13:21:53.407963Z","shell.execute_reply.started":"2023-08-03T13:21:51.105805Z","shell.execute_reply":"2023-08-03T13:21:53.406414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Architecture üë∑","metadata":{"id":"xXhUSgRkMA_D"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.models as models\n\n\ndensenet = models.densenet121(pretrained=True)\nnum_ftrs = densenet.classifier.in_features\n\n# Replace the classifier with a custom fully connected layer followed by the Sigmoid activation\ndensenet.classifier = nn.Linear(num_ftrs, 2)\n","metadata":{"id":"fXU87aY8ZC2D","execution":{"iopub.status.busy":"2023-08-03T13:22:17.951190Z","iopub.execute_input":"2023-08-03T13:22:17.951576Z","iopub.status.idle":"2023-08-03T13:22:18.485189Z","shell.execute_reply.started":"2023-08-03T13:22:17.951540Z","shell.execute_reply":"2023-08-03T13:22:18.484119Z"},"outputId":"400baf63-5685-4b63-e9d2-773554a265b6","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining The Train Function üöÇ\n","metadata":{"id":"pfRFxAC0MA_D"}},{"cell_type":"code","source":"def train(model, dataloader, loss_fn, optimizer, device, ldl, lts): ## ldl = length dataloader, lts = length dataset\n    model.train()  ## puts the model on training mode such as enabling gradient computations\n    total_loss = 0 ## over current epoch\n\n    total_correct = 0 ## extra, calculate the accuracy on training set during epoch\n    for batch in tqdm(dataloader):\n        inputs, labels = batch[0].to(device), batch[1].to(device)\n        optimizer.zero_grad() ## deletes stored gradients\n        outputs = model(inputs)\n\n        loss = loss_fn(outputs, labels)\n\n        loss.backward()     ## computes gradients\n        optimizer.step()    ## updates parameters\n\n        total_loss += loss.item()\n\n        predictions = outputs.argmax(dim=1)\n\n        correct = (predictions == labels).sum().item()\n        total_correct += correct\n\n    return total_loss / ldl, total_correct / lts","metadata":{"id":"qJxrENNtMA_E","execution":{"iopub.status.busy":"2023-08-03T13:22:18.486895Z","iopub.execute_input":"2023-08-03T13:22:18.487747Z","iopub.status.idle":"2023-08-03T13:22:18.498928Z","shell.execute_reply.started":"2023-08-03T13:22:18.487699Z","shell.execute_reply":"2023-08-03T13:22:18.497798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Accuracy Function üéØ\n","metadata":{"id":"yWUMRFlQMA_E"}},{"cell_type":"code","source":"def compute_accuracy(dataloader, model):\n    model.eval()  # switch to evaluation mode\n\n    total_correct = 0\n    total_count = 0\n    with torch.no_grad():\n        for batch in dataloader:\n            inputs, labels = batch[0].to(device), batch[1].to(device)\n            outputs = model(inputs)\n            predictions = outputs.argmax(dim=1)\n            correct = (predictions == labels).sum().item()\n            total_correct += correct\n            total_count += len(labels)\n\n    accuracy = total_correct / total_count\n\n    return accuracy\n","metadata":{"id":"gBchV282MA_E","execution":{"iopub.status.busy":"2023-08-03T13:22:18.500950Z","iopub.execute_input":"2023-08-03T13:22:18.501418Z","iopub.status.idle":"2023-08-03T13:22:18.513600Z","shell.execute_reply.started":"2023-08-03T13:22:18.501373Z","shell.execute_reply":"2023-08-03T13:22:18.512397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Initialization & Configuration ‚öôÔ∏è\n","metadata":{"id":"96mSARohMA_E"}},{"cell_type":"code","source":"import torch.optim as optim\n\nmodel = densenet ## initialize the model\n# model= nn.DataParallel(model) ## incase you want to use the x2 gpu option you'd need to enable this\n\nldl = len(trainloader) ## fixed\n\nbestScore = 0\npatience = 6          # if model accuracy on validation dataset didn't improve for 10 epochs it will stop and save highest scoring model\nnum_epochs = 30\nloss_fn = nn.CrossEntropyLoss()\nbest_epoch = 0\n\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n#optimizer = optim.Adam(model.parameters(), lr=0.001)\n# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n\n\n## select the device that we will train the model on\nif(torch.cuda.is_available()):\n    device = torch.device('cuda')\nelif(torch.backends.mps.is_available()): ## for the macbook users :)\n    device = torch.device('mps')\nelse:\n    device = torch.device('cpu')\n\nmodel.to(device)","metadata":{"id":"ggQCrpSrMA_E","outputId":"12b608e0-a5b1-44d7-e4f4-fd8585327cc5","execution":{"iopub.status.busy":"2023-08-03T13:22:18.525211Z","iopub.execute_input":"2023-08-03T13:22:18.525677Z","iopub.status.idle":"2023-08-03T13:22:24.364551Z","shell.execute_reply.started":"2023-08-03T13:22:18.525616Z","shell.execute_reply":"2023-08-03T13:22:24.363495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Training Loop üöÇ üîÅ\n","metadata":{"id":"mdelgz7hMA_E"}},{"cell_type":"code","source":"# the following lists will be used to plot the loss and accuracy curves by keeping track of the values over epochs\ntrain_losses = []\ncross_accs = []\ntrain_accs = []\nlr = []\nfor epoch in range(num_epochs):\n    train_loss, train_acc = train(model, trainloader, loss_fn, optimizer, device, ldl, ldl*batch_size)\n    CurrentScore = compute_accuracy(crossloader, model)\n\n    lr.append(optimizer.param_groups[0]['lr'])\n    train_losses.append(train_loss)\n    cross_accs.append(CurrentScore)\n    train_accs.append(train_acc)\n    clear_output(wait=True) # wait for all plots to be shown, then erase them and display the updated ones\n\n    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, lr: {lr[-1]:.7f}')\n    print(f'Cross Acc: {CurrentScore:.4f}, Train Acc: {train_acc:.4f}')\n    # scheduler.step()\n\n    # initialize 3 subplots to plot the loss curve, learning rate curve and accuracy curve\n    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n    axs[0].plot(train_losses)\n    axs[0].set_title('Training Loss')\n    axs[1].plot(lr)\n    axs[1].set_title('Learning Rate')\n    axs[2].plot(cross_accs, label=\"cross\")\n    axs[2].plot(train_accs, label = \"train\")\n    axs[2].set_title('Cross/Train Accuracy')\n    axs[2].legend()\n    plt.show(block=False)\n    print(\"Patience REM : \", epoch - best_epoch)\n    if CurrentScore > bestScore:\n        bestScore = CurrentScore\n        best_epoch = epoch\n        torch.save(model.state_dict(), 'best_model.pt')\n    elif epoch - best_epoch >= patience:\n        print(f'Validation loss did not improve for {patience} epochs. Training stopped.')\n        break","metadata":{"id":"G1op0UnnMA_E","outputId":"3d4ee566-028a-42fe-ee0d-a49c40bb2254","execution":{"iopub.status.busy":"2023-08-03T13:22:24.366642Z","iopub.execute_input":"2023-08-03T13:22:24.367914Z","iopub.status.idle":"2023-08-03T13:33:58.009401Z","shell.execute_reply.started":"2023-08-03T13:22:24.367872Z","shell.execute_reply":"2023-08-03T13:33:58.005202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Back The Best Model üîô\n\n","metadata":{"id":"zruX1QNCMA_F"}},{"cell_type":"code","source":"model.load_state_dict(torch.load('/content/best_model.pt', map_location=device))","metadata":{"id":"T8DZxoYMMA_F","outputId":"95cb45ac-fc2b-4603-fa6e-d4424aa97ae3","execution":{"iopub.status.busy":"2023-08-03T13:33:58.011248Z","iopub.execute_input":"2023-08-03T13:33:58.011992Z","iopub.status.idle":"2023-08-03T13:33:58.168713Z","shell.execute_reply.started":"2023-08-03T13:33:58.011953Z","shell.execute_reply":"2023-08-03T13:33:58.167560Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Getting model Predictions üìù\nwe now will pass the best performing model state, into this function, which will return a list containing our labels","metadata":{"id":"So2sKgZ3MA_F"}},{"cell_type":"code","source":"def getPreds(dataloader, models):\n    preds = []\n    with torch.no_grad():\n        for batch in dataloader:\n            inputs = batch[0].to(device)\n            outputs = model(inputs)\n            predictions = outputs.argmax(dim=1)\n            preds.extend(predictions.cpu().numpy())\n\n    return preds","metadata":{"id":"IwYltcoBMA_F","execution":{"iopub.status.busy":"2023-08-03T13:33:58.170316Z","iopub.execute_input":"2023-08-03T13:33:58.170725Z","iopub.status.idle":"2023-08-03T13:33:58.179532Z","shell.execute_reply.started":"2023-08-03T13:33:58.170689Z","shell.execute_reply":"2023-08-03T13:33:58.178456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Test Data üì•","metadata":{}},{"cell_type":"code","source":"test_set = CustomDataset('/content/PlantFinal Files-20230213T190104Z-001/Final Files/test/','/content/PlantFinal Files-20230213T190104Z-001/Final Files/test.csv', transform=transform_test)\ntestloader = DataLoader(test_set, batch_size=32, shuffle=False)\ntest_data = pd.read_csv('/content/PlantFinal Files-20230213T190104Z-001/Final Files/test.csv')\nfilenames = test_data['Filename']","metadata":{"id":"l-3p8TBqQYW-","execution":{"iopub.status.busy":"2023-08-03T13:34:22.672590Z","iopub.execute_input":"2023-08-03T13:34:22.673651Z","iopub.status.idle":"2023-08-03T13:34:22.705055Z","shell.execute_reply.started":"2023-08-03T13:34:22.673615Z","shell.execute_reply":"2023-08-03T13:34:22.703999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving Submission Data üíΩ","metadata":{"id":"sNplUi7xMA_F"}},{"cell_type":"code","source":"preds = getPreds(testloader, model)\nsubmn = pd.DataFrame({'Filename' : filenames,'Label': preds})\nsubmn.to_csv('subm.csv', index=False)\nsubmn","metadata":{"id":"mxQjOK4eMA_F","outputId":"10179536-57b1-44d3-f8c5-659d970a7510","execution":{"iopub.status.busy":"2023-08-03T13:34:23.679273Z","iopub.execute_input":"2023-08-03T13:34:23.679712Z","iopub.status.idle":"2023-08-03T13:34:40.393579Z","shell.execute_reply.started":"2023-08-03T13:34:23.679668Z","shell.execute_reply":"2023-08-03T13:34:40.392509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"gJm2rzevMC4S"},"execution_count":null,"outputs":[]}]}